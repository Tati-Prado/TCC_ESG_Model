{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d9c91934",
      "metadata": {
        "id": "d9c91934"
      },
      "source": [
        "### TCC 6 – individual - Tatiana Prado Santos Massoco\n",
        "\n",
        "# Desenvolvimento de Modelo Preditivo de Risco ESG para Investimentos Sustentáveis\n",
        "\n",
        "Fonte de daddos: https://www.kaggle.com/datasets/tunguz/environment-social-and-governance-data/data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aff0c245",
      "metadata": {
        "id": "aff0c245"
      },
      "source": [
        "# Introdução\n",
        "\n",
        "## Definição do Tema\n",
        "O projeto tem como objetivo o desenvolvimento de um **modelo preditivo de riscos ESG (Environmental, Social, Governance) para investimentos sustentáveis**. Este modelo permitirá identificar e analisar riscos associados a fatores ESG, possibilitando decisões mais informadas e alinhadas com critérios de sustentabilidade.\n",
        "\n",
        "- **Por que escolhi este tema?**\n",
        "\n",
        "O tema é relevante para atender à crescente demanda por análises baseadas em ESG, especialmente no contexto de finanças sustentáveis e responsabilidade corporativa.\n",
        "\n",
        "## Como os Indicadores ESG Influenciam Decisões de Investimento?\n",
        "Os investidores utilizam métricas ESG para alinhar suas decisões com valores sustentáveis e mitigar riscos associados a práticas inadequadas de governança, impacto ambiental ou vulnerabilidades sociais. Abaixo estão os principais impactos dos indicadores ESG nas decisões de investimento:\n",
        "\n",
        "- **Mitigação de Riscos:** indicadores como emissões de CO₂ ou nitrous oxide revelam vulnerabilidades ambientais que podem acarretar sanções regulatórias, desastres naturais ou perda de reputação.\n",
        "\n",
        "\n",
        "- **Identificação de Oportunidades:** métricas de inovação, como pedidos de patentes, indicam competitividade e adaptação tecnológica, que frequentemente estão ligadas a oportunidades de crescimento e retorno no longo prazo.\n",
        "\n",
        "\n",
        "- **Atração de Capital:** empresas e países com altos índices de igualdade de gênero, inclusão social ou investimento em educação frequentemente atraem capital de investidores que priorizam governança moderna e responsabilidade social.\n",
        "\n",
        "\n",
        "- **Eficácia Operacional:** indicadores relacionados à eficiência energética ou acesso à eletricidade sinalizam maior controle de custos e maior produtividade, aumentando a atratividade de investimentos.\n",
        "\n",
        "\n",
        "- **Resiliência a Crises:** governos ou empresas com baixa desigualdade (Gini Index) e políticas de redistribuição de renda são mais resilientes a crises econômicas e sociais, criando um ambiente de investimento mais previsível.\n",
        "\n",
        "\n",
        "## Aplicação da Base de Dados escolhida para treinamento do modelo:\n",
        "\n",
        "Os países na base de dados serão analisados de forma semelhante à forma como empresas seriam analisadas para investimentos em um contexto de avaliação ESG (Ambiental, Social e Governança). Essa abordagem é válida, pois muitos indicadores utilizados (como emissões de carbono, igualdade social e governança) são aplicáveis tanto a empresas quanto a países, especialmente quando o objetivo é avaliar riscos e oportunidades de investimento sustentável.\n",
        "\n",
        "\n",
        "**Razões para usar essa abordagem:**\n",
        "\n",
        "- Indicadores ESG como Avaliadores de Risco: assim como em empresas, indicadores ESG para países ajudam a identificar riscos relacionados a políticas ambientais, estabilidade social e práticas de governança. Por exemplo:\n",
        "    - Um país com altas emissões de carbono pode enfrentar regulamentações mais severas ou custos mais elevados para transição energética.\n",
        "    - Problemas sociais, como desemprego elevado ou baixa escolaridade, podem impactar a produtividade e a estabilidade econômica.\n",
        "    - Governança fraca, como corrupção ou desigualdade extrema, aumenta o risco de instabilidade política e econômica.\n",
        "    \n",
        "    \n",
        "**Impacto no Investimento:**\n",
        "\n",
        "- Investidores utilizam ESG para avaliar como fatores não financeiros podem afetar retornos no longo prazo. Isso é válido ao considerar países, especialmente em decisões relacionadas a:\n",
        "    - Investimento em títulos soberanos.\n",
        "    - Alocação de recursos em projetos de infraestrutura ou desenvolvimento.\n",
        "    - Escolha de regiões para operar negócios.\n",
        "    \n",
        "\n",
        "**Metodologia Similar:**\n",
        "\n",
        "- Tanto para empresas quanto para países, a análise ESG envolve:\n",
        "    - Identificar fatores de risco e oportunidade em cada pilar (E, S, G).\n",
        "    - Estabelecer métricas relevantes e comparáveis.\n",
        "    - Justificar decisões com base em dados robustos\n",
        "\n",
        "## Descrição do Banco de Dados\n",
        "\n",
        "O banco de dados contém informações relacionadas a métricas de ESG (Ambiental, Social e Governança) organizadas em formato de séries temporais para diversos países. Aqui estão os principais pontos sobre a estrutura do arquivo:\n",
        "\n",
        "**Estrutura do banco de dados**\n",
        "\n",
        "Colunas principais:\n",
        "- **Country Name**: Nome do país.\n",
        "- **Country Code**: Código ISO de três letras do país.\n",
        "- **Indicator Name**: Nome do indicador.\n",
        "- **Indicator Code**: Código do indicador.\n",
        "- **Anos**: os dados estão organizados por ano, começando em 1960, com algumas colunas extras, como \"2050\" (provavelmente para projeções futuras) e uma coluna não nomeada (**Unnamed: 66**), que parece conter apenas valores nulos.\n",
        "\n",
        "**Exemplos de Indicadores:**\n",
        "\n",
        "A coluna **Indicator Name** contém 33 indicadores únicos, como por exemplo:\n",
        "\n",
        "- **Ambiental**:\n",
        "  - \"Access to clean fuels and technologies for cooking (% of population)\": Acesso a combustíveis limpos e tecnologias para cozinhar.\n",
        "  - \"Adjusted savings: net forest depletion (% of GNI)\": Depleção líquida de florestas como percentual do GNI.\n",
        "- **Social**:\n",
        "  - \"Access to electricity (% of population)\": Percentual da população com acesso à eletricidade.\n",
        "- **Governança**:\n",
        "  - \"Government expenditure on education, total (% of government expenditure)\": Investimento governamental em educação.\n",
        "\n",
        "Valores: Cada célula para um ano específico contém o valor do indicador para aquele país e ano (quando disponível).\n",
        "\n",
        "#### O que representam os números nas métricas do indicadores?\n",
        "\n",
        "- **Valores Absolutos ou Percentuais**: dependendo do indicador, esses números podem ser:\n",
        "  - Um valor absoluto (ex.: toneladas de CO₂ per capita, kWh por pessoa).\n",
        "  - Um percentual (ex.: % de eletricidade proveniente de carvão, % de área florestal).\n",
        "  - Uma taxa ou proporção (ex.: razão entre homens e mulheres no mercado de trabalho).\n",
        "  \n",
        "\n",
        "- **Indicador Específico**: cada número reflete a medição ou estimativa do indicador para aquele ano e país. Por exemplo:\n",
        "  - Se o indicador é \"CO2 emissions (metric tons per capita)\", o valor de 1960 para \"Arab World\" reflete a quantidade média de CO₂ emitida per capita naquela região em 1960.\n",
        "\n",
        "#### Como esses números são calculados?\n",
        "\n",
        "1. **Fontes de Dados**: os valores vêm de medições ou estimativas realizadas por órgãos governamentais, organizações internacionais (como o Banco Mundial ou a ONU), ou agências de pesquisa.\n",
        "   - **Exemplo**: Emissões de CO₂ são estimadas a partir de dados de consumo de combustíveis fósseis, produção industrial e uso de energia.\n",
        "\n",
        "2. **Metodologias Específicas por Indicador**:\n",
        "\n",
        "   - **Indicadores Ambientais**:\n",
        "     - CO2 emissions: calculado usando o consumo de combustíveis fósseis e fatores de emissão padrão por tipo de combustível.\n",
        "     - Methane/Nitrous oxide emissions: baseado em atividades agrícolas, industriais e manejo de resíduos.\n",
        "     - Forest area (%): medido por imagens de satélite e estimativas de perda/florestamento.\n",
        "\n",
        "   - **Indicadores Sociais**:\n",
        "     - Life expectancy: calculado usando taxas de mortalidade específicas por idade.\n",
        "     - Literacy rate: percentual de adultos alfabetizados baseado em censos nacionais.\n",
        "\n",
        "   - **Indicadores de Governança**:\n",
        "     - Gini index: calculado a partir de distribuições de renda coletadas em pesquisas nacionais.\n",
        "     - Patent applications: número total de patentes registradas em agências locais.\n",
        "\n",
        "3. **Ajustes e Normalizações**:\n",
        "   - Dados podem ser ajustados para eliminar discrepâncias entre países ou tornar os indicadores comparáveis (ex.: converter energia para \"equivalentes de petróleo\").\n",
        "\n",
        "4. **Atualizações e Projeções**:\n",
        "   - Para anos futuros (como \"2050\"), os valores podem ser projeções baseadas em modelos estatísticos e tendências históricas.\n",
        "\n",
        "#### Como verificar a origem e o cálculo exato?\n",
        "\n",
        "- **Documentação**: Cada indicador geralmente tem uma documentação associada que descreve detalhadamente a fonte dos dados e as metodologias de cálculo. No Kaggle, por exemplo, essa informação está disponível no arquivo de descrição do dataset ou no link da fonte original: https://datacatalog.worldbank.org/search/dataset/0037651\n",
        "\n",
        "\n",
        "- **Organizações Referentes**:\n",
        "  - Indicadores ambientais: IPCC, Banco Mundial.\n",
        "  - Indicadores sociais: UNESCO, OMS.\n",
        "  - Indicadores de governança: Banco Mundial, relatórios de desenvolvimento humano.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38fa5819",
      "metadata": {
        "id": "38fa5819"
      },
      "source": [
        "---\n",
        "\n",
        "# Planejamento do Projeto - Parte 1\n",
        "\n",
        "## Arquitetura do Projeto\n",
        "\n",
        "### Estrutura do Projeto\n",
        "\n",
        "- `data/`: Armazena os datasets do projeto.\n",
        "- `src/`: Contém os scripts Python para análise e processamento de dados.\n",
        "- `notebooks/` (talvez apagarei): Cadernos Jupyter para análises exploratórias.\n",
        "- `esg_model_env/`: Ambiente virtual para gerenciar dependências.\n",
        "- `README.md`: Documentação do projeto.\n",
        "- `requirements.txt`: Lista de dependências do projeto.\n",
        "- `modelos_deploy_src/`: Contém os modelos treinados.\n",
        "\n",
        "### Ferramentas e Tecnologias\n",
        "\n",
        "- **Análise Exploratória:** Jupyter Notebook com Anaconda.\n",
        "- **Python**: Para análise de dados, pré-processamento e construção do modelo.\n",
        "- **Bibliotecas utilizadas**: pandas, numpy, seaborn, Scikit-learn, matplotlib, Flask, xgboost, joblib, os.\n",
        "- **Kernel:** Python (esg_model_env)\n",
        "- **Deploy:** Docker para containerização.\n",
        "- **Git**: Controle de versão e rastreamento de alterações no projeto.\n",
        "- **GitHub**: Para hospedagem do repositório remoto e colaboração.\n",
        "- **Ambiente virtual (venv)**: Gerenciamento de dependências do projeto.\n",
        "- **MLOps:** MLflow para controle de versões e Prometheus/Grafana para métricas.\n",
        "\n",
        "### Componentes Chave:\n",
        "\n",
        "**ETL Pipeline:**\n",
        "\n",
        "Conjunto de processos utilizados para extrair, transformar e carregar dados de uma ou várias fontes em um destino:\n",
        "\n",
        "- Extração e carregamento dos dados do Kaggle (dados ESG).\n",
        "- Transformações aplicadas durante o pré-processamento, incluindo cálculos do ESG Risk Score.\n",
        "\n",
        "**Modelo de Machine Learning:**\n",
        "\n",
        "- Algoritmos de classificação e/ou regressão para prever o nível de risco ESG.\n",
        "\n",
        "**Serviço em Produção:**\n",
        "\n",
        "- API desenvolvida com Flask para facilitar previsões de risco ESG em tempo real.\n",
        "\n",
        "**Monitoramento e Manutenção:**\n",
        "- Prometheus e Grafana para monitoramento em produção.\n",
        "- CI/CD com GitHub Actions para automação do deploy.\n",
        "\n",
        "\n",
        "## Pipeline do Projeto\n",
        "\n",
        "### Coleta e Pré-processamento dos Dados:\n",
        "\n",
        "- **Entrada:** Conjunto de dados ESG do Kaggle.\n",
        "- **Transformações:**\n",
        "\n",
        "  - Limpeza de dados.\n",
        "  - Cálculo de métricas como ESG Risk Score com base em pesos definidos.\n",
        "  \n",
        "\n",
        "### Treinamento e Validação do Modelo:\n",
        "\n",
        "- Divisão do conjunto de dados em treino e teste.\n",
        "- Seleção de algoritmos de classificação e regressão.\n",
        "- Validação cruzada para garantir robustez.\n",
        "\n",
        "### Automação com CI/CD:\n",
        "\n",
        "- GitHub Actions configurado para automatizar testes e deploy.\n",
        "- Docker utilizado para empacotamento e execução em produção.\n",
        "\n",
        "\n",
        "### Monitoramento em Produção:\n",
        "\n",
        "- Prometheus para coleta de métricas.\n",
        "- Grafana para visualização de dashboards e alertas.\n",
        "- Retreinamento baseado em mudanças nos dados ou desempenho do modelo.\n",
        "\n",
        "### Manutenção e Atualizações:\n",
        "\n",
        "- Logs detalhados de todas as versões do modelo.\n",
        "- Retreinamento automático integrado no pipeline.\n",
        "\n",
        "## Decisões Tomadas e Justificativas\n",
        "\n",
        "### Por que usei Python?\n",
        "Python é uma linguagem versátil com um ecossistema rico para análise de dados e machine learning, além de sua ampla aceitação na comunidade de ciência de dados.\n",
        "\n",
        "### Por que criei um repositório no Git?\n",
        "A criação do repositório Git garante que todas as alterações no projeto sejam rastreadas, promovendo um fluxo de trabalho organizado e permitindo colaborações futuras.\n",
        "\n",
        "### Por que implementei a análise de outliers?\n",
        "Identificar valores extremos é essencial para garantir que os dados não prejudiquem a qualidade do modelo preditivo. Isso ajuda a decidir quais ajustes são necessários, como normalizações ou transformações.\n",
        "\n",
        "### Por que adotei a transformação logarítmica?\n",
        "A transformação logarítmica foi aplicada para normalizar as distribuições de dados com alta variância, o que facilita a análise e melhora a performance dos modelos preditivos.\n",
        "\n",
        "## Códigos e Alterações Realizadas (ver VS Code)\n",
        "### Código Inicial\n",
        "```python\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Caminho para o dataset principal\n",
        "caminho_dataset = \"/Users/tatiana.massoco/Desktop/TCC_ESG_Model/data/ESGData.csv\"\n",
        "\n",
        "# Carregar o dataset\n",
        "dados = pd.read_csv(caminho_dataset)\n",
        "\n",
        "# Informações do dataset\n",
        "print(dados.info())\n",
        "```\n",
        "\n",
        "### Código Alterado com Análise de Outliers\n",
        "```python\n",
        "# Identificar outliers para anos específicos\n",
        "anos_para_analisar = [\"1960\", \"1970\", \"1980\", \"1990\", \"2000\", \"2010\", \"2020\"]\n",
        "for ano in anos_para_analisar:\n",
        "    if ano in dados.columns:\n",
        "        outliers = dados[[ano, \"Country Name\", \"Country Code\"]].sort_values(by=ano, ascending=False).head(10)\n",
        "        print(f\"Valores mais altos para o ano {ano}:\")\n",
        "        print(outliers)\n",
        "```\n",
        "\n",
        "### Código Alterado com Transformação Logarítmica\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Aplicar transformação logarítmica\n",
        "anos_para_transformacao = [\"1960\", \"1970\", \"1980\", \"1990\", \"2000\", \"2010\", \"2020\"]\n",
        "for ano in anos_para_transformacao:\n",
        "    if ano in dados.columns:\n",
        "        dados[f\"{ano}_log\"] = np.log1p(dados[ano])\n",
        "        print(f\"Transformação logarítmica aplicada para o ano {ano}\")\n",
        "```\n",
        "\n",
        "## Próximos Passos\n",
        "1. Visualizar as distribuições transformadas para comparar com as originais.\n",
        "2. Selecionar os indicadores mais relevantes para o modelo preditivo.\n",
        "3. Normalizar as colunas e lidar com valores ausentes de forma sistemática.\n",
        "4. Iniciar o pré-processamento final dos dados para construção do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2428e59c",
      "metadata": {
        "id": "2428e59c"
      },
      "source": [
        "---\n",
        "\n",
        "## Planejamento do Projeto - Parte 2\n",
        "\n",
        "**Estrutura do Projeto Atual**\n",
        "- Diretório principal: `TCC_ESG_Model`\n",
        "  - `data/`: Contém os datasets utilizados no projeto.\n",
        "  - `esg_model_env/`: Ambiente virtual configurado.\n",
        "  - `Imagens_data_cleaning/`: Imagens geradas durante a análise de dados.\n",
        "  - `notebooks/`: Pasta destinada aos notebooks Jupyter.\n",
        "  - `README.md`: Arquivo de descrição do projeto.\n",
        "  - `requirements.txt`: Lista de dependências do projeto.\n",
        "  - `src/`: Scripts Python organizados para cada etapa do pipeline.\n",
        "  \n",
        "\n",
        "**Decisões Tomadas e Justificativas**\n",
        "\n",
        "1. **Estrutura do Projeto**\n",
        "\n",
        "   - A organização foi definida para manter um fluxo de trabalho claro e reprodutível.\n",
        "   - Scripts separados em `src/` permitem modularidade e reutilização do código.\n",
        "   - Notebooks para prototipagem rápida (pasta `notebooks/`) facilitam a análise interativa.\n",
        "   \n",
        "\n",
        "2. **Uso do Controle de Versão com Git**\n",
        "\n",
        "   - Justificativa: Acompanhar mudanças no código, garantir colaboração eficiente e versionar todas as etapas.\n",
        "   - Comandos principais utilizados:\n",
        "     - `git add`: Para adicionar arquivos ou alterações ao controle de versão.\n",
        "     - `git commit`: Para salvar as alterações localmente com mensagens claras.\n",
        "     - `git push`: Para sincronizar o repositório local com o remoto no GitHub.\n",
        "     \n",
        "\n",
        "3. **Uso do Jupyter Notebook**\n",
        "\n",
        "   - Decisão de utilizar notebooks para as etapas de:\n",
        "     - Análise Exploratória de Dados (EDA).\n",
        "     - Prototipagem de Modelos.\n",
        "   - Justificativa: Maior facilidade na visualização de dados e na documentação interativa.\n",
        "\n",
        "4. **Automação com Scripts**\n",
        "\n",
        "   - Scripts criados para limpeza de dados (`src/data_cleaning.py`) e, futuramente, para modelagem e deploy.\n",
        "   - Justificativa: Garantir que processos repetitivos sejam automatizados.\n",
        "\n",
        "**Passos Executados**\n",
        "\n",
        "1. **Transformação Logarítmica e Visualização**\n",
        "\n",
        "   - Implementado no script `src/data_cleaning.py`:\n",
        "     - Transformação logarítmica aplicada aos anos específicos (1960, 1970, ... 2020).\n",
        "     - Gráficos gerados para analisar as distribuições transformadas.\n",
        "\n",
        "2. **Preparação para Análise Exploratória**\n",
        "\n",
        "   - Decisão de utilizar o Jupyter Notebook para criar o arquivo `notebooks/EDA.ipynb`.\n",
        "   - Incluir análise de correlação, tendências, e gráficos interativos.\n",
        "\n",
        "**Próximos Passos**\n",
        "\n",
        "1. **Finalizar Limpeza de Dados**\n",
        "\n",
        "   - Validar distribuições transformadas.\n",
        "   - Salvar dataset limpo e pronto para análise em `data/ESGData_cleaned.csv`.\n",
        "\n",
        "2. **Iniciar Análise Exploratória**\n",
        "\n",
        "   - Criar o arquivo `EDA.ipynb` e realizar as análises sugeridas:\n",
        "     - Estatísticas descritivas.\n",
        "     - Identificação de padrões e correlações.\n",
        "\n",
        "3. **Controle de Versão para Notebooks**\n",
        "\n",
        "   - Configurar commits frequentes usando os comandos Git diretamente no terminal:\n",
        "     - `git add Nome_do_Notebook.ipynb`\n",
        "     - `git commit -m \"Descrição\"`\n",
        "     - `git push origin main`.\n",
        "\n",
        "4. **Instalação do nbgitpuller (Opcional)**\n",
        "\n",
        "   - Extensão para facilitar o controle de versão dentro do Jupyter Notebook.\n",
        "   - Comando para instalação:\n",
        "     ```\n",
        "     pip install nbgitpuller\n",
        "     ```\n",
        "   - Justificativa: Automatizar sincronização de notebooks para colaboração.\n",
        "\n",
        "**Recomendações**\n",
        "\n",
        "- Manter a documentação clara no README.md para facilitar o entendimento do projeto.\n",
        "- Sempre validar as alterações antes de realizar commits.\n",
        "- Utilizar notebooks para análises iterativas e scripts para automação.\n",
        "\n",
        "**Observações**\n",
        "Este documento será atualizado conforme o progresso do projeto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1c55de5",
      "metadata": {
        "id": "b1c55de5"
      },
      "source": [
        "---\n",
        "\n",
        "# Planejamento do Projeto - Parte 3\n",
        "\n",
        "## Análise das Distribuições Logarítmicas\n",
        "\n",
        "### Resultado da Transformação Logarítmica\n",
        "- A transformação logarítmica foi aplicada aos anos selecionados (1960, 1970, 1980, 1990, 2000, 2010, 2020).\n",
        "- Gráficos de distribuição logarítmica foram gerados para observar a nova distribuição dos dados após a transformação.\n",
        "- Os resultados mostraram que:\n",
        "  - Os valores extremos foram suavizados.\n",
        "  - A transformação ajudou a reduzir a assimetria dos dados em alguns casos.\n",
        "\n",
        "### Por Que Tomei Esta Decisão?\n",
        "1. **Transformação logarítmica:** Reduz a influência de outliers e normaliza os dados, o que melhora a performance de muitos modelos de machine learning.\n",
        "2. **Foco em anos relevantes:** Analisar o impacto da transformação nos dados históricos e recentes ajuda a decidir quais períodos utilizar na modelagem.\n",
        "\n",
        "---\n",
        "\n",
        "## Revisão de Dados Ausentes\n",
        "\n",
        "### Próxima Etapa\n",
        "Agora, antes de prosseguir com a análise exploratória e modelagem, é necessário tratar os dados ausentes, pois:\n",
        "- Valores ausentes podem causar erros na modelagem.\n",
        "- Decisões sobre exclusão ou imputação afetam diretamente a qualidade do modelo.\n",
        "\n",
        "### Decisões Tomadas\n",
        "\n",
        "1. **Explorar os dados ausentes:**\n",
        "   - Verificar a proporção de valores ausentes por coluna e linha.\n",
        "   - Identificar padrões nos dados ausentes.\n",
        "   \n",
        "2. **Definir estratégia de tratamento:**\n",
        "   - Remoção de colunas com muitos valores ausentes (ex.: mais de 50% ausentes).\n",
        "   - Imputação de valores usando mediana, interpolação ou preenchimento com valor padrão.\n",
        "   \n",
        "\n",
        "### Por Que Tomei Esta Decisão?\n",
        "\n",
        "1. **Qualidade dos dados:** Garantir que o conjunto final esteja limpo e utilizável.\n",
        "2. **Relevância:** Permitir que anos recentes (2010-2020) sejam priorizados na modelagem.\n",
        "3. **Eficiência do pipeline:** A limpeza agora facilita todas as etapas subsequentes.\n",
        "\n",
        "---\n",
        "\n",
        "## Ações a Serem Tomadas\n",
        "\n",
        "### Atualizar o Script `data_cleaning.py`\n",
        "- Incluir análise e tratamento de valores ausentes no pipeline.\n",
        "\n",
        "### Próximos Passos\n",
        "1. Adicionar o código para análise de dados ausentes.\n",
        "2. Decidir estratégias para tratamento (remoção, imputação).\n",
        "3. Gerar o dataset atualizado após o tratamento.\n",
        "4. Verificar os resultados do tratamento e validar as alterações.\n",
        "\n",
        "### Controle de Versão\n",
        "- Após cada modificação no `data_cleaning.py`, realizar commit e push para o repositório GitHub:\n",
        "```bash\n",
        "git add src/data_cleaning.py\n",
        "git commit -m \"Adiciona tratamento de dados ausentes ao pipeline de limpeza\"\n",
        "git push origin main\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Planejamento do Projeto - Resumo Atualizado\n",
        "1. **Limpeza e Transformação Inicial (Concluído):**\n",
        "   - Remoção de colunas irrelevantes.\n",
        "   - Aplicação de transformação logarítmica.\n",
        "2. **Tratamento de Dados Ausentes (Em Progresso):**\n",
        "   - Analisar e tratar valores ausentes para garantir um dataset limpo.\n",
        "3. **Análise Exploratória e Modelagem (Futuro):**\n",
        "   - Utilizar os dados transformados e tratados para análise e construção de modelos.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57506569",
      "metadata": {
        "id": "57506569"
      },
      "source": [
        "\n",
        "# Planejamento do Projeto - Parte 4\n",
        "\n",
        "## **Resumo das Atividades Realizadas**\n",
        "\n",
        "### **Análise de Valores Ausentes**\n",
        "\n",
        "1. **Visualização com Mapa de Calor**:\n",
        "\n",
        "![Figure_MapaCalor_ValorAusente.png](attachment:Figure_MapaCalor_ValorAusente.png)\n",
        "\n",
        "   - Foi gerado um mapa de calor para identificar a distribuição de valores ausentes ao longo do dataset.\n",
        "   - No mapa de calor:\n",
        "        - Amarelo = valores ausentes.\n",
        "        - Roxo = valores presentes.\n",
        "\n",
        "\n",
        "2. **Porcentagem de Valores Ausentes por Coluna**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fb7b8f5",
      "metadata": {
        "id": "1fb7b8f5",
        "outputId": "ea62c225-4ca5-42ca-ac66-9006cad4fe35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1960    91.556860\n",
            "2020    97.108599\n",
            "2050    95.178917\n",
            "dtype: float64\n",
            "1990    58.808468\n",
            "1991    59.339287\n",
            "1992    56.797602\n",
            "1993    58.177731\n",
            "1994    57.852994\n",
            "1995    56.116905\n",
            "1996    50.271654\n",
            "1997    54.418285\n",
            "1998    48.504340\n",
            "1999    54.911634\n",
            "2001    47.854868\n",
            "2003    40.317242\n",
            "2015    40.092425\n",
            "2016    46.505964\n",
            "2017    53.656404\n",
            "2018    58.171486\n",
            "dtype: float64\n",
            "Country Name       0.000000\n",
            "Country Code       0.000000\n",
            "Indicator Name     0.000000\n",
            "Indicator Code     0.000000\n",
            "2000              38.724786\n",
            "2002              38.119028\n",
            "2004              39.193156\n",
            "2005              37.132330\n",
            "2006              38.662337\n",
            "2007              36.370449\n",
            "2008              38.943359\n",
            "2009              37.844252\n",
            "2010              35.621058\n",
            "2011              37.138575\n",
            "2012              35.439955\n",
            "2013              39.143196\n",
            "2014              38.431275\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar o dataset limpo\n",
        "df = pd.read_csv('/Users/tatiana.massoco/Desktop/TCC_ESG_Model/data/ESGData_clean.csv')\n",
        "\n",
        "# Calcular a porcentagem de valores ausentes para cada coluna\n",
        "missing_percentage = df.isnull().sum() / len(df) * 100\n",
        "\n",
        "# Exibir as colunas com valores ausentes acima de 90%\n",
        "print(missing_percentage[missing_percentage > 90])\n",
        "\n",
        "# Exibir as colunas com valores ausentes entre 40% e 60%\n",
        "print(missing_percentage[(missing_percentage >= 40) & (missing_percentage <= 60)])\n",
        "\n",
        "# Exibir as colunas com menos de 40% de valores ausentes\n",
        "print(missing_percentage[missing_percentage < 40])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0b7a7d5",
      "metadata": {
        "id": "d0b7a7d5"
      },
      "source": [
        " - Análise das Porcentagens de Valores Ausentes por Coluna\n",
        "\n",
        "Colunas com Altas Porcentagens de Valores Ausentes (>90%):\n",
        "\n",
        "- 1960: 91.56%\n",
        "- 2020: 97.11%\n",
        "- 2050: 95.18%\n",
        "\n",
        "Essas colunas possuem muitos valores ausentes e podem não ser adequadas para modelagem, a menos que você implemente estratégias de imputação robustas.\n",
        "\n",
        "Colunas Intermediárias (1990-2000): Valores Ausentes Variando Entre 40-60%:\n",
        "\n",
        "- Exemplos:\n",
        "\n",
        "  - 1990: 58.81%\n",
        "  - 1993: 58.18%\n",
        "  - 1998: 48.50%\n",
        "\n",
        "Essas colunas estão no meio-termo, com lacunas significativas, mas podem ser úteis dependendo das estratégias de preenchimento ou exclusão.\n",
        "\n",
        "Colunas com Menores Porcentagens de Valores Ausentes (<40%):\n",
        "\n",
        "- 2000-2015:\n",
        "\n",
        "  - 2000: 38.72%\n",
        "  - 2010: 35.62%\n",
        "  - 2012: 35.44%\n",
        "\n",
        "Essas colunas são as mais completas, especialmente para anos mais recentes, tornando-as mais adequadas para modelagem.\n",
        "\n",
        "Interpretação e Uso:\n",
        "\n",
        "- Para modelagem ou análise de séries temporais:\n",
        "\n",
        "  - Utilizar preferencialmente os dados mais recentes (anos após 2000), que possuem menos valores ausentes.\n",
        "  \n",
        "- Para imputação ou limpeza de dados:\n",
        "\n",
        "  - Foco em anos intermediários (1990-2000) pode ser viável com estratégias adequadas de preenchimento.\n",
        "  \n",
        "- Descarte inicial:\n",
        "\n",
        "  - Colunas como 1960, 2020 e 2050 podem ser descartadas temporariamente, já que a falta de dados é significativa.\n",
        "\n",
        "\n",
        "## **Decisões Tomadas**\n",
        "\n",
        "1. **Porque Decidi Tratar Valores Ausentes**:\n",
        "\n",
        "   - Garantir que os dados utilizados no modelo sejam robustos e minimizem o impacto de informações faltantes.\n",
        "   - Facilitar a análise exploratória e a modelagem sem introduzir viés por dados inconsistentes.\n",
        "\n",
        "2. **Decisão de Estratégia para Valores Ausentes**:\n",
        "\n",
        "   - Remover colunas com mais de 90% de valores ausentes, pois essas colunas têm pouca contribuição para a modelagem.\n",
        "   - Remover linhas que possuem mais de 50% de valores ausentes, para eliminar registros incompletos.\n",
        "   - Preencher valores ausentes restantes com a mediana das respectivas colunas, garantindo que os dados permaneçam representativos.\n",
        "\n",
        "## **Próximos Passos**\n",
        "\n",
        "### **Implementação do Tratamento de Valores Ausentes**\n",
        "\n",
        "1. **Etapas a Seguir**:\n",
        "\n",
        "   - Adicionar ao script `src/data_cleaning.py` o código para:\n",
        "   \n",
        "     - Remover colunas com mais de 90% de valores ausentes.\n",
        "     - Remover linhas com mais de 50% de valores ausentes.\n",
        "     - Preencher valores ausentes restantes com a mediana das colunas.\n",
        "\n",
        "2. **Workflow**:\n",
        "\n",
        "   - Após implementar o código, executar o script e revisar o dataset resultante.\n",
        "   - Realizar um novo commit com as alterações.\n",
        "\n",
        "3. **Próxima Decisão**:\n",
        "\n",
        "   - Validar o impacto do tratamento de valores ausentes no dataset e decidir como seguir com a análise exploratória.\n",
        "\n",
        "---\n",
        "\n",
        "**Estrutura do Código Adicionado:**\n",
        "```python\n",
        "# 9. Lidar com valores ausentes\n",
        "\n",
        "# Remover colunas com mais de 90% de valores ausentes\n",
        "limite_colunas = 90  # Limite percentual\n",
        "colunas_para_remover = valores_ausentes[valores_ausentes > limite_colunas].index\n",
        "dados = dados.drop(columns=colunas_para_remover)\n",
        "print(f\"\\nColunas removidas por exceder {limite_colunas}% de valores ausentes: {list(colunas_para_remover)}\")\n",
        "\n",
        "# Remover linhas com mais de 50% de valores ausentes\n",
        "limite_linhas = len(dados.columns) * 0.5  # 50% do total de colunas\n",
        "dados = dados.dropna(thresh=limite_linhas, axis=0)\n",
        "print(f\"\\nLinhas restantes após remoção de linhas com mais de 50% de valores ausentes: {len(dados)}\")\n",
        "\n",
        "# Preencher valores ausentes restantes com a mediana da coluna\n",
        "dados = dados.fillna(dados.median())\n",
        "print(\"\\nValores ausentes restantes preenchidos com a mediana das colunas.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**Status Atual**:\n",
        "O projeto avança para garantir que o dataset final esteja pronto para análise exploratória e modelagem, com foco em dados mais recentes e representativos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd2f09d8",
      "metadata": {
        "id": "dd2f09d8"
      },
      "source": [
        "---\n",
        "\n",
        "# Planejamento do Projeto - Parte 5\n",
        "\n",
        "## **Atualizações do Projeto**\n",
        "1. - Finalizei a limpeza de dados no script `src/data_cleaning.py`.\n",
        "2. - Resolvi desafios relacionados ao tratamento de valores ausentes nas colunas numéricas.\n",
        "3. - Gerei e salvei o arquivo final do dataset limpo: `ESGData_clean_final.csv`.\n",
        "\n",
        "\n",
        "\n",
        "## Contexto\n",
        "\n",
        "Nesta etapa, o foco foi preparar um conjunto de dados estruturado e limpo para a análise exploratória de dados (EDA). Durante o processo, foram encontrados desafios relacionados a valores ausentes e erros no código, que precisaram ser corrigidos para garantir a consistência dos dados.\n",
        "\n",
        "\n",
        "## Desafios Enfrentados\n",
        "\n",
        "1. **Valores Ausentes nas Colunas Numéricas**:\n",
        "   - Muitas colunas numéricas apresentavam valores ausentes. Inicialmente, foi tentado preencher todas as colunas utilizando a mediana, mas isso gerou problemas ao incluir colunas categóricas no cálculo.\n",
        "\n",
        "2. **Erro de Conversão**:\n",
        "   - Durante o preenchimento, ocorreu o erro `TypeError: Cannot convert [...] to numeric`, causado pela tentativa de calcular a mediana em colunas não numéricas.\n",
        "\n",
        "3. **Problemas no Terminal**:\n",
        "   - Algumas execuções apresentaram falhas devido a conflitos no ambiente virtual. Foi necessário reativar o ambiente com:\n",
        "     ```\n",
        "     source esg_model_env/bin/activate\n",
        "     ```\n",
        "\n",
        "4. **Validação do Arquivo de Saída**:\n",
        "   - Após cada execução, foi necessário verificar se o arquivo `ESGData_clean.csv` ou `ESGData_clean_final.csv` estava sendo atualizado corretamente.\n",
        "\n",
        "\n",
        "## Decisões Tomadas\n",
        "\n",
        "1. **Selecionar Apenas Colunas Numéricas**:\n",
        "   - Atualizei o código para usar `select_dtypes` e garantir que apenas colunas numéricas fossem preenchidas com a mediana. Isso eliminou os erros de conversão.\n",
        "\n",
        "2. **Revisão Manual**:\n",
        "   - Validei os arquivos de saída gerados em cada etapa para confirmar que os valores ausentes foram tratados corretamente.\n",
        "\n",
        "3. **Planejamento da EDA**:\n",
        "   - Decidi avançar para a análise exploratória de dados utilizando o notebook `EDA.ipynb` para realizar visualizações e explorar correlações e padrões no conjunto de dados.\n",
        "\n",
        "\n",
        "## Passos Executados\n",
        "\n",
        "1. **Ajuste no Preenchimento de Valores Ausentes**:\n",
        "   - Modifiquei o script para tratar apenas colunas numéricas, utilizando a mediana para preencher os valores ausentes.\n",
        "   \n",
        "**Lidar com valores ausentes**: código - remover colunas com mais de 90% de valores ausentes\n",
        "\n",
        "2. **Atualização do Repositório Git**:\n",
        "   - Controle de versão foi mantido com os seguintes comandos:\n",
        "     ```\n",
        "     git add src/data_cleaning.py\n",
        "     git commit -m \"Corrige preenchimento de valores ausentes para colunas numéricas\"\n",
        "     git push origin main\n",
        "     ```\n",
        "\n",
        "3. **Geração do Dataset Final**:\n",
        "   - Após ajustes e validações, o arquivo limpo foi salvo como `ESGData_clean_final.csv`.\n",
        "\n",
        "\n",
        "## Próximos Passos\n",
        "\n",
        "1. **Criação do Notebook EDA.ipynb**:\n",
        "   - Desenvolver o arquivo `EDA.ipynb` para realizar análises como:\n",
        "     - Estatísticas descritivas.\n",
        "     - Identificação de padrões e correlações.\n",
        "\n",
        "2. **Exploração Interativa**:\n",
        "   - Usar o notebook para criar gráficos e análises detalhadas dos indicadores ESG.\n",
        "\n",
        "3. **Documentação**:\n",
        "   - Atualizar o README.md com as etapas concluídas, incluindo detalhes sobre o dataset final e os desafios superados.\n",
        "\n",
        "\n",
        "## Conclusão\n",
        "\n",
        "Apesar dos desafios enfrentados, o conjunto de dados foi limpo com sucesso, e os valores ausentes foram tratados adequadamente. O próximo passo será explorar os dados para identificar tendências e padrões que possam guiar a modelagem preditiva."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2649e2c",
      "metadata": {
        "id": "a2649e2c"
      },
      "source": [
        "---\n",
        "\n",
        "Planejamento do Projeto - Parte 6\n",
        "=================================\n",
        "\n",
        "**Atualizações do Projeto**\n",
        "Nesta etapa, concentrei-me na organização do repositório, no controle de versão e na preparação para a análise exploratória de dados (EDA) no notebook Jupyter.\n",
        "\n",
        "**Decisões Tomadas e Justificativas**\n",
        "1. **Atualização do Repositório no GitHub**:\n",
        "   - Incluí os arquivos limpos, imagens geradas durante a etapa de limpeza e o novo notebook `EDA.ipynb`.\n",
        "   - Justificativa: Garantir que o repositório contenha todas as informações relevantes para análise futura.\n",
        "\n",
        "2. **Remoção de Arquivos Temporários (.DS_Store)**:\n",
        "   - Removi todos os arquivos `.DS_Store` do repositório e atualizei o `.gitignore` para evitar que esses arquivos sejam adicionados novamente.\n",
        "   - Justificativa: Manter o repositório limpo e organizado, evitando arquivos desnecessários.\n",
        "\n",
        "3. **Criação do Notebook de EDA**:\n",
        "   - Criei o arquivo `EDA.ipynb` na pasta `notebooks/`.\n",
        "   - Justificativa: Iniciar a análise exploratória de dados de maneira interativa e documentar insights e padrões.\n",
        "\n",
        "**Passos Executados**\n",
        "1. **Adição de Arquivos ao GitHub**:\n",
        "   - Adicionei os seguintes itens ao repositório:\n",
        "     - Arquivo final de dados limpos: `ESGData_clean_final.csv`.\n",
        "     - Imagens geradas na etapa de limpeza, salvas na pasta `Imagens_data_cleaning/`.\n",
        "     - Notebook de EDA: `EDA.ipynb`.\n",
        "   - Comandos utilizados:\n",
        "     ```\n",
        "     git add .\n",
        "     git commit -m \"Add cleaned data files, images, and EDA notebook\"\n",
        "     git push origin main\n",
        "     ```\n",
        "\n",
        "2. **Remoção de Arquivos Temporários**:\n",
        "   - Removi os arquivos `.DS_Store` e atualizei o `.gitignore`:\n",
        "     - Comandos utilizados:\n",
        "       ```\n",
        "       git rm --cached .DS_Store Imagens_data_cleaning/.DS_Store data/.DS_Store\n",
        "       git commit -m \"Remove .DS_Store and update .gitignore\"\n",
        "       git push origin main\n",
        "       ```\n",
        "\n",
        "3. **Preparação do Ambiente para EDA**:\n",
        "   - Ativei o ambiente virtual e confirmei que todos os pacotes necessários estão instalados.\n",
        "   - Verifiquei que o notebook `EDA.ipynb` está pronto para uso.\n",
        "\n",
        "**Próximos Passos**\n",
        "1. **Análise Exploratória de Dados (EDA)**:\n",
        "   - Iniciar o trabalho no notebook `EDA.ipynb`, incluindo:\n",
        "     - Estatísticas descritivas para entender a distribuição dos dados.\n",
        "     - Gráficos interativos para identificar correlações entre os indicadores ESG.\n",
        "\n",
        "2. **Documentação**:\n",
        "   - Registrar os resultados e decisões tomadas durante a EDA no notebook.\n",
        "   - Atualizar o README.md para incluir informações sobre o progresso do projeto.\n",
        "\n",
        "3. **Planejamento de Modelagem**:\n",
        "   - Após a EDA, planejar a implementação do modelo preditivo para avaliação de risco ESG.\n",
        "\n",
        "**Conclusão**\n",
        "Com o repositório atualizado e o notebook de EDA preparado, estou pronta para explorar o conjunto de dados limpo e identificar padrões e insights que irão orientar as próximas etapas do projeto.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2be4f878",
      "metadata": {
        "id": "2be4f878"
      },
      "source": [
        "---\n",
        "\n",
        "Planejamento do Projeto - Parte 7\n",
        "=================================\n",
        "\n",
        "**Atualizações do Projeto**\n",
        "- Durante esta etapa, defini os indicadores-chave para os três pilares do ESG (Ambiental, Social e Governança).\n",
        "- Justifiquei a seleção dos indicadores com base em referências confiáveis e alinhadas às práticas de investimento ESG.\n",
        "- Finalizei a estrutura conceitual para as próximas etapas do EDA, focando nos indicadores definidos.\n",
        "\n",
        "**Decisões Tomadas e Justificativas**\n",
        "1. **Definição de Indicadores-Chave**\n",
        "   - Escolhi 20 indicadores distribuídos entre os pilares Ambiental, Social e Governança.\n",
        "   - Justificativa: Esses indicadores representam fatores relevantes que influenciam o risco ESG de países, conforme literatura e práticas de mercado.\n",
        "\n",
        "2. **Priorização de Indicadores Relevantes**\n",
        "   - Foquei nos indicadores que têm maior impacto no desempenho ESG, com base em dados confiáveis e critérios bem definidos.\n",
        "   - Justificativa: Priorização permite uma análise mais eficiente e direcionada, eliminando dados redundantes.\n",
        "\n",
        "3. **Planejamento do EDA**\n",
        "   - Estruturei os próximos passos do EDA para explorar distribuições, correlações e tendências temporais com base nos indicadores-chave.\n",
        "   - Justificativa: Garantir que o EDA forneça insights claros e utilizáveis para o modelo preditivo.\n",
        "\n",
        "**Próximos Passos**\n",
        "1. **Exploração de Distribuições**\n",
        "   - Criar histogramas para visualizar a distribuição de valores dos indicadores-chave selecionados, observando padrões e possíveis outliers.\n",
        "   - Ajustar o tamanho dos gráficos para melhor visualização e documentação.\n",
        "\n",
        "2. **Análise de Correlações**\n",
        "   - Gerar uma matriz de correlação entre os indicadores-chave para identificar relações significativas.\n",
        "\n",
        "3. **Tendências Temporais**\n",
        "   - Visualizar como os indicadores-chave mudam ao longo do tempo para diferentes países.\n",
        "\n",
        "4. **Atualização do Notebook**\n",
        "   - Documentar cada etapa executada no notebook `EDA.ipynb`, incluindo análises e gráficos.\n",
        "\n",
        "5. **Próxima Atualização do Planejamento**\n",
        "   - Após executar as análises mencionadas acima, revisar este documento e detalhar as decisões tomadas e os próximos passos subsequentes.\n",
        "\n",
        "**Observações**\n",
        "Este documento será atualizado conforme o progresso do projeto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b21a2685",
      "metadata": {
        "id": "b21a2685"
      },
      "source": [
        "---\n",
        "\n",
        "Planejamento do Projeto - Parte 8\n",
        "=================================\n",
        "\n",
        "**Atualizações do Projeto**  \n",
        "\n",
        "- Nesta etapa, iniciei a exploração de distribuições dos indicadores ESG selecionados por meio de histogramas e curvas de densidade (KDE) para identificar padrões, outliers e tendências.  \n",
        "- Documentei observações importantes sobre as distribuições dos indicadores-chave, como tendências gerais e outliers significativos.  \n",
        "- Realizei commits para atualizar o repositório com os avanços realizados no EDA e nos notebooks associados.  \n",
        "\n",
        "**Decisões Tomadas e Justificativas**  \n",
        "\n",
        "1. **Análise de Distribuições dos Indicadores**  \n",
        "\n",
        "   - Decisão: Gerar gráficos para visualizar a distribuição de valores dos indicadores selecionados para os anos 1970, 1980, 1990, 2000 e 2010.  \n",
        "   - Justificativa: Entender a dispersão e os padrões gerais dos dados é fundamental para a etapa de modelagem.  \n",
        "\n",
        "2. **Documentação no Notebook**  \n",
        "\n",
        "   - Decisão: Atualizar o notebook `EDA.ipynb` com as análises realizadas, incluindo gráficos gerados e observações dos outputs.  \n",
        "   - Justificativa: Manter a transparência e o registro claro do progresso do projeto.  \n",
        "\n",
        "\n",
        "**Passos Executados**  \n",
        "\n",
        "1. **Exploração de Distribuições**  \n",
        "\n",
        "   - Criei histogramas para os indicadores do pilar ambiental, observando distribuições enviesadas à direita e a presença de outliers.  \n",
        "   - Documentei observações relacionadas à dispersão crescente ao longo do tempo e fatores associados aos outliers.  \n",
        "\n",
        "     ```\n",
        "\n",
        "**Próximos Passos**  \n",
        "1. **Automatizar Análise de Distribuições**  \n",
        "   - Desenvolver um loop para gerar gráficos de distribuição automaticamente para todos os indicadores selecionados de cada pilar (Ambiental, Social, Governança).  \n",
        "\n",
        "2. **Revisar Outputs**  \n",
        "   - Identificar padrões gerais e priorizar indicadores com distribuições incomuns ou que apresentem desafios específicos para análise detalhada.  \n",
        "\n",
        "3. **Preparar para Análise de Correlações**  \n",
        "   - Criar uma matriz de correlação para os indicadores-chave e explorar relações significativas.  \n",
        "\n",
        "4. **Documentar no Notebook**  \n",
        "   - Continuar a registrar as etapas e observações no notebook `EDA.ipynb` para manter uma linha de progresso clara e consistente.  \n",
        "\n",
        "**Observações**  \n",
        "Este documento será atualizado novamente após a execução das próximas etapas planejadas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f3596a1",
      "metadata": {
        "id": "4f3596a1"
      },
      "source": [
        "Planejamento do Projeto - Parte 9\n",
        "=================================\n",
        "\n",
        "**Atualizações do Projeto**\n",
        "\n",
        "Nesta etapa, finalizei a análise exploratória de dados (EDA) para os indicadores ESG, abrangendo os pilares Ambiental, Social e Governança. Além disso, documentei os padrões identificados e defini os próximos passos para o desenvolvimento do modelo preditivo de risco ESG para investimentos sustentáveis.\n",
        "\n",
        "**Análises Realizadas**\n",
        "\n",
        "1. **Exploração de Distribuições**\n",
        "\n",
        "   - Criação de histogramas com curvas de densidade (KDE) para visualizar a distribuição dos valores dos indicadores selecionados por ano e pilar.\n",
        "   - Identificação de padrões gerais, outliers e tendências.\n",
        "\n",
        "2. **Análise Estatística**\n",
        "\n",
        "   - Coleta de estatísticas descritivas (mínimo, máximo, média, desvio padrão) para os indicadores selecionados.\n",
        "   - Identificação de outliers e indicadores constantes.\n",
        "\n",
        "3. **Interpretação dos Resultados**\n",
        "\n",
        "   - Verificação da dependência de combustíveis fósseis e emissões altas em vários países.\n",
        "   - Identificação de tendências positivas em indicadores sociais e econômicos, mas com desigualdades ainda perceptíveis.\n",
        "\n",
        "**Decisões Tomadas e Justificativas**\n",
        "\n",
        "1. **Tratar Outliers**\n",
        "\n",
        "   - Decidi verificar os países responsáveis pelos valores extremos em indicadores como \"CO2 emissions\".\n",
        "   - Justificativa: Outliers podem impactar significativamente o desempenho do modelo.\n",
        "\n",
        "2. **Investigar Dados Constantes**\n",
        "\n",
        "   - Indicadores com desvio padrão zero, como \"Income share held by lowest 20% em 1970\", serão analisados para determinar sua relevância.\n",
        "   - Justificativa: Dados constantes podem não agregar valor à análise.\n",
        "\n",
        "3. **Explorar Correlações**\n",
        "\n",
        "   - Criação de uma matriz de correlação para identificar relações significativas entre os indicadores.\n",
        "   - Justificativa: Entender as interdependências dos indicadores é essencial para criar um modelo robusto.\n",
        "\n",
        "4. **Visualizar Tendências Temporais**\n",
        "\n",
        "   - Criação de gráficos de linha para visualizar a evolução dos indicadores ao longo do tempo.\n",
        "   - Justificativa: Identificar mudanças e tendências históricas pode ajudar a prever padrões futuros.\n",
        "\n",
        "**Próximos Passos**\n",
        "\n",
        "1. **Tratar Outliers**\n",
        "\n",
        "   - Identificar os países com valores extremos para os indicadores selecionados.\n",
        "   - Decidir entre normalização, transformação logarítmica ou exclusão desses valores.\n",
        "\n",
        "2. **Investigar Dados Constantes**\n",
        "\n",
        "   - Avaliar a relevância de indicadores com desvio padrão zero ou valores constantes.\n",
        "\n",
        "3. **Explorar Correlações**\n",
        "\n",
        "   - Gerar uma matriz de correlação para identificar relações significativas entre os indicadores ESG.\n",
        "\n",
        "4. **Preparar Dados para Modelagem**\n",
        "\n",
        "   - Realizar a normalização e padronização dos dados.\n",
        "   - Dividir o dataset em conjuntos de treino, validação e teste.\n",
        "\n",
        "5. **Desenvolver o Modelo Preditivo**\n",
        "\n",
        "   - Selecionar algoritmos de aprendizado de máquina para prever o risco ESG.\n",
        "   - Treinar o modelo e ajustar hiperparâmetros.\n",
        "\n",
        "6. **Implementar o Modelo**\n",
        "\n",
        "   - Criar um pipeline para implantação do modelo em produção.\n",
        "   - Integrar monitoramento contínuo para avaliar o desempenho do modelo.\n",
        "\n",
        "7. **Documentar Resultados**\n",
        "\n",
        "   - Atualizar o notebook com observações, gráficos e decisões tomadas durante o processo.\n",
        "   - Criar um relatório final para apresentação do projeto.\n",
        "\n",
        "**Justificativa para o Planejamento**\n",
        "\n",
        "As etapas definidas garantem que cada aspecto relevante dos dados seja tratado adequadamente antes de iniciar a modelagem. Isso minimiza erros e melhora a robustez do modelo preditivo de risco ESG.\n",
        "\n",
        "**Observações**\n",
        "\n",
        "Este documento será atualizado conforme o progresso do projeto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8050dc2",
      "metadata": {
        "id": "c8050dc2"
      },
      "source": [
        "## Planejamento do Projeto - Parte 10\n",
        "\n",
        "**Atualizações do Projeto**\n",
        "\n",
        "Nesta etapa, foquei na identificação e tratamento de outliers, uma análise detalhada essencial para assegurar a consistência e a confiabilidade dos dados antes de avançar para a modelagem preditiva. Além disso, documentei os resultados e ajustei o planejamento para as próximas etapas do projeto.\n",
        "\n",
        "**Análises Realizadas**\n",
        "\n",
        "1. **Identificação de Outliers**\n",
        "   - Apliquei análises baseadas no intervalo interquartil (IQR) para detectar outliers nos indicadores selecionados.\n",
        "   - Listei os países responsáveis pelos valores extremos para cada indicador, agrupados por ano.\n",
        "\n",
        "2. **Documentação dos Resultados**\n",
        "   - Registrei as observações de outliers para cada pilar (Ambiental, Social e Governança), detalhando os países e valores associados.\n",
        "\n",
        "3. **Planejamento para Tratamento de Outliers**\n",
        "   - Avaliei diferentes abordagens para tratar os outliers:\n",
        "     - Normalização.\n",
        "     - Transformação logarítmica.\n",
        "     - Exclusão de valores extremos.\n",
        "\n",
        "**Decisões Tomadas e Justificativas**\n",
        "\n",
        "1. **Registrar Outliers Identificados**\n",
        "   - Optei por documentar cada outlier identificado antes de decidir sobre o tratamento.\n",
        "   - **Justificativa:** Ter uma visão clara dos outliers ajuda a planejar estratégias específicas para tratamento.\n",
        "\n",
        "2. **Definir Estratégia de Tratamento**\n",
        "   - Para indicadores onde outliers refletem características naturais (e.g., emissões de CO2 em países industrializados), decidi usar transformações como logaritmos.\n",
        "   - Para valores extremos com impacto mínimo na análise, optei por exclusão.\n",
        "   - **Justificativa:** Garantir que os dados sejam representativos sem distorcer padrões reais.\n",
        "\n",
        "3. **Preparação para Correlações**\n",
        "   - A análise de outliers será seguida por uma matriz de correlação para entender interdependências entre indicadores.\n",
        "   - **Justificativa:** Facilitar a identificação de variáveis relevantes para a modelagem.\n",
        "\n",
        "**Próximos Passos**\n",
        "\n",
        "1. **Tratar Outliers**\n",
        "   - Aplicar as estratégias definidas para cada indicador e documentar o impacto no dataset.\n",
        "\n",
        "2. **Explorar Correlações**\n",
        "   - Criar e interpretar uma matriz de correlação abrangente.\n",
        "   - Identificar variáveis altamente correlacionadas para modelagem.\n",
        "\n",
        "3. **Preparar os Dados**\n",
        "   - Realizar normalização e padronização, conforme necessário.\n",
        "   - Dividir os dados em conjuntos de treino, validação e teste.\n",
        "\n",
        "4. **Iniciar a Modelagem Preditiva**\n",
        "   - Selecionar os algoritmos apropriados para prever o risco ESG.\n",
        "   - Implementar um pipeline automatizado para facilitar ajustes e treinamentos.\n",
        "\n",
        "5. **Documentar o Progresso**\n",
        "   - Atualizar o notebook com todas as decisões e resultados obtidos.\n",
        "\n",
        "**Justificativa para o Planejamento**\n",
        "\n",
        "A abordagem detalhada garante que os dados estejam prontos para modelagem, minimizando vieses causados por outliers e maximizando a robustez do modelo preditivo.\n",
        "\n",
        "**Observações**\n",
        "\n",
        "O documento será atualizado com novos insights e decisões tomadas durante as etapas subsequentes do projeto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53df4163",
      "metadata": {
        "id": "53df4163"
      },
      "source": [
        "### Tratamento de Outliers\n",
        "\n",
        "**Objetivo**\n",
        "Normalizar, transformar ou excluir valores extremos, garantindo que os dados sejam representativos para a modelagem.\n",
        "\n",
        "**Ações Planejadas**\n",
        "1. Revisar o impacto dos outliers por indicador e por ano.\n",
        "2. Testar transformações logarítmicas ou normalizações onde aplicável.\n",
        "3. Atualizar o notebook `EDA.ipynb` com observações e decisões tomadas durante o processo.\n",
        "\n",
        "**Etapas Detalhadas**\n",
        "1. **Revisão do Impacto dos Outliers**\n",
        "   - Identificar os valores extremos presentes em cada indicador ESG.\n",
        "   - Analisar a influência desses valores na distribuição geral e em estatísticas descritivas.\n",
        "\n",
        "2. **Aplicação de Transformações**\n",
        "   - Testar transformações logarítmicas para suavizar distribuições enviesadas.\n",
        "   - Avaliar o impacto da normalização em indicadores com grande variância.\n",
        "\n",
        "3. **Atualização e Documentação**\n",
        "   - Inserir gráficos comparativos (antes e depois das transformações) no notebook.\n",
        "   - Documentar decisões e justificar a escolha de manter, transformar ou excluir outliers.\n",
        "\n",
        "**Decisões e Justificativas**\n",
        "1. **Transformações Logarítmicas**\n",
        "   - Serão aplicadas onde valores extremos distorcem a análise, como emissões de CO2.\n",
        "   - **Justificativa:** Suavizar distribuições e melhorar a robustez do modelo.\n",
        "\n",
        "2. **Exclusão de Outliers**\n",
        "   - Outliers sem impacto significativo nos resultados gerais poderão ser removidos.\n",
        "   - **Justificativa:** Garantir que os dados sejam representativos sem viés desnecessário.\n",
        "\n",
        "3. **Normalização**\n",
        "   - Indicadores com escalas discrepantes serão normalizados.\n",
        "   - **Justificativa:** Aumentar a compatibilidade com algoritmos de aprendizado de máquina.\n",
        "\n",
        "**Próximos Passos Após o Tratamento de Outliers**\n",
        "1. Investigar Dados Constantes.\n",
        "2. Explorar Correlações.\n",
        "3. Preparar Dados para Modelagem.\n",
        "4. Desenvolver o Modelo Preditivo.\n",
        "5. Documentar Resultados e Relatórios.\n",
        "\n",
        "**Acompanhamento**\n",
        "- Após cada etapa, documentar os resultados e decisões no notebook correspondente.\n",
        "- Realizar commits frequentes no repositório para manter o controle de versão.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bf3e466",
      "metadata": {
        "id": "1bf3e466"
      },
      "source": [
        "## Planejamento do Projeto - Parte 11\n",
        "\n",
        "**Atualizações do Projeto**  \n",
        "Nesta etapa, concluí o tratamento de outliers e validei as alterações realizadas no dataset. Além disso, defini os próximos passos relacionados à exploração de correlações e preparação dos dados para modelagem, garantindo uma estrutura robusta para o desenvolvimento do modelo preditivo.\n",
        "\n",
        "**Análises Realizadas**  \n",
        "\n",
        "1. **Tratamento de Outliers**  \n",
        "   - Apliquei transformações logarítmicas para lidar com os valores extremos em indicadores específicos.  \n",
        "   - **Indicadores tratados:**  \n",
        "     - **Ambiental:** CO2 emissions (metric tons per capita), Methane emissions, Energy use, entre outros.  \n",
        "     - **Social:** Indicadores como Life expectancy e Individuals using the Internet.  \n",
        "     - **Governança:** Gini index, Government expenditure on education, entre outros.  \n",
        "   - As transformações visaram reduzir o impacto dos valores extremos sem excluí-los, mantendo a integridade dos dados.  \n",
        "\n",
        "2. **Validação do Dataset**  \n",
        "   - Verifiquei a consistência do dataset após as transformações:  \n",
        "     - Nenhum valor ausente foi identificado.  \n",
        "     - Estatísticas descritivas confirmaram que os dados estão consistentes e prontos para as próximas etapas.  \n",
        "   - Visualizei os dados transformados por meio de boxplot, que mostrou uma redução significativa na dispersão causada pelos outliers.  \n",
        "\n",
        "**Decisões Tomadas e Justificativas**  \n",
        "\n",
        "1. **Manutenção de Outliers Transformados**  \n",
        "   - Decidi utilizar transformações logarítmicas ao invés de exclusão de outliers.  \n",
        "   - **Justificativa:** Garantir que as características dos dados sejam preservadas, ao mesmo tempo em que reduzo o impacto de valores extremos no modelo.  \n",
        "\n",
        "2. **Validação Visual**  \n",
        "   - Decidi utilizar gráficos de boxplot para verificar o impacto das transformações nos indicadores.  \n",
        "   - **Justificativa:** A validação visual ajuda a garantir que as alterações feitas no dataset atingiram os objetivos planejados.  \n",
        "\n",
        "**Próximos Passos**  \n",
        "\n",
        "1. **Explorar Correlações**  \n",
        "   - Gerar a matriz de correlação para identificar possíveis redundâncias e interdependências entre os indicadores.  \n",
        "   - Avaliar a necessidade de remover ou combinar variáveis com alta correlação.  \n",
        "\n",
        "2. **Preparar Dados para Modelagem**  \n",
        "   - Normalizar e padronizar os dados para garantir compatibilidade com algoritmos de aprendizado de máquina.  \n",
        "   - Dividir o dataset em conjuntos de treino, validação e teste.  \n",
        "\n",
        "3. **Desenvolver o Modelo Preditivo**  \n",
        "   - Escolher algoritmos adequados para o problema em questão.  \n",
        "   - Treinar o modelo e ajustar hiperparâmetros para otimizar o desempenho.  \n",
        "\n",
        "4. **Documentar Resultados**  \n",
        "   - Atualizar o notebook com todas as observações, gráficos e decisões tomadas durante o processo.  \n",
        "   - Preparar um relatório inicial consolidando as análises realizadas até o momento.  \n",
        "\n",
        "**Justificativa para o Planejamento**  \n",
        "As etapas definidas garantem que o dataset está limpo, consistente e pronto para ser usado no desenvolvimento de modelos preditivos. O planejamento de tarefas relacionadas à análise de correlações e preparação de dados busca eliminar redundâncias e melhorar a performance dos algoritmos.  \n",
        "\n",
        "**Observações**  \n",
        "Este documento será atualizado conforme o progresso do projeto.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94179af6",
      "metadata": {
        "id": "94179af6"
      },
      "source": [
        "## Planejamento do Projeto - Parte 12\n",
        "\n",
        "**Atualizações do Projeto**  \n",
        "Nesta etapa, concluí a remoção de indicadores altamente correlacionados, apliquei normalização aos dados restantes e dividi o dataset em conjuntos para modelagem. Essas ações foram realizadas para assegurar que o modelo preditivo seja desenvolvido com dados limpos e equilibrados.\n",
        "\n",
        "---\n",
        "\n",
        "### **Análises Realizadas**\n",
        "\n",
        "1. **Exploração de Correlações**  \n",
        "   - Gerada uma matriz de correlação para identificar indicadores com correlação maior ou igual a 0.95.  \n",
        "   - Removidos indicadores redundantes para evitar multicolinearidade no modelo.  \n",
        "   - **Indicadores removidos:** {'1963', '1975', '2000', ..., '2017', '1991', '2015'}.  \n",
        "\n",
        "2. **Normalização dos Dados**  \n",
        "   - Aplicada a função `StandardScaler` aos indicadores selecionados.  \n",
        "   - A normalização colocou os dados na mesma escala, facilitando o aprendizado dos algoritmos de machine learning.  \n",
        "\n",
        "3. **Divisão do Dataset**  \n",
        "   - O dataset foi dividido em três partes:  \n",
        "     - **Treino:** 70% dos dados, usados para treinar o modelo.  \n",
        "     - **Validação:** 15% dos dados, usados para ajuste de hiperparâmetros.  \n",
        "     - **Teste:** 15% dos dados, usados para avaliar o desempenho final.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Decisões Tomadas e Justificativas**\n",
        "\n",
        "1. **Remoção de Indicadores Altamente Correlacionados**  \n",
        "   - **Decisão:** Remover indicadores redundantes.  \n",
        "   - **Justificativa:** Minimizar multicolinearidade e garantir que o modelo capture informações únicas de cada variável.  \n",
        "\n",
        "2. **Normalização**  \n",
        "   - **Decisão:** Normalizar os dados usando `StandardScaler`.  \n",
        "   - **Justificativa:** Algoritmos de machine learning, como regressão logística e redes neurais, performam melhor com dados normalizados.  \n",
        "\n",
        "3. **Divisão do Dataset**  \n",
        "   - **Decisão:** Adotar a proporção 70-15-15 para treino, validação e teste.  \n",
        "   - **Justificativa:** Garantir uma amostra significativa para treinar e testar o modelo sem comprometer a representatividade.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Próximos Passos**\n",
        "\n",
        "1. **Desenvolvimento do Modelo Preditivo**  \n",
        "   - Escolher algoritmos adequados para o problema (ex.: regressão logística, árvores de decisão, etc.).  \n",
        "   - Treinar e ajustar hiperparâmetros usando os conjuntos de treino e validação.  \n",
        "\n",
        "2. **Avaliação do Modelo**  \n",
        "   - Avaliar o desempenho nos dados de teste.  \n",
        "   - Analisar métricas como precisão, recall e F1-score para validar a eficácia do modelo.  \n",
        "\n",
        "3. **Documentação**  \n",
        "   - Atualizar o notebook com gráficos, códigos e observações.  \n",
        "   - Consolidar os resultados em um relatório formal para apresentação.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Justificativa para o Planejamento**  \n",
        "As ações executadas garantem que o dataset foi preparado adequadamente para modelagem, reduzindo riscos de overfitting e assegurando a representatividade dos dados. A estrutura de divisão do dataset segue as melhores práticas para validação de modelos preditivos.\n",
        "\n",
        "**Observações**\n",
        "\n",
        "Este documento será atualizado conforme o progresso do projeto.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8748cb35",
      "metadata": {
        "id": "8748cb35"
      },
      "source": [
        "## Planejamento do Projeto - Parte 13\n",
        "\n",
        "### Atualizações do Projeto\n",
        "Nesta etapa, foquei na preparação dos dados para modelagem preditiva, abrangendo todas as variáveis-alvo relevantes dos pilares Ambiental, Social e Governança. Realizei ajustes nas divisões de treino e teste, garantindo consistência e qualidade nos conjuntos de dados gerados para cada variável-alvo.\n",
        "\n",
        "---\n",
        "\n",
        "### Análises Realizadas\n",
        "\n",
        "**1. Preparação do Dataset para Cada Variável-Alvo**\n",
        "Dividi os dados em conjuntos de treino e teste para as seguintes variáveis-alvo:\n",
        "\n",
        "**Pilar Ambiental:**  \n",
        "- **CO2 emissions (metric tons per capita):** Avalia contribuições às mudanças climáticas.  \n",
        "- **Methane emissions (metric tons of CO2 equivalent per capita):** Impacto climático significativo.  \n",
        "- **Nitrous oxide emissions (metric tons of CO2 equivalent per capita):** Relacionado ao aquecimento global.  \n",
        "- **Energy use (kg of oil equivalent per capita):** Mede a eficiência energética.  \n",
        "- **Fossil fuel energy consumption (% of total):** Dependência de combustíveis fósseis.  \n",
        "- **Electricity production from coal sources (% of total):** Transição para fontes de energia limpas.  \n",
        "- **Forest area (% of land area):** Preservação ambiental.  \n",
        "- **Adjusted savings: natural resources depletion (% of GNI):** Exploração de recursos naturais.  \n",
        "\n",
        "**Pilar Social:**  \n",
        "- **Life expectancy at birth, total (years):** Saúde e qualidade de vida.  \n",
        "- **Literacy rate, adult total (% of people ages 15 and above):** Desenvolvimento educacional.  \n",
        "- **School enrollment, primary and secondary (gross), gender parity index (GPI):** Igualdade educacional entre gêneros.  \n",
        "- **Prevalence of overweight (% of adults):** Indicador de saúde pública.  \n",
        "- **Individuals using the Internet (% of population):** Inclusão digital.  \n",
        "- **Access to electricity (% of population):** Infraestrutura básica.  \n",
        "\n",
        "**Pilar Governança:**  \n",
        "- **Gini index (World Bank estimate):** Desigualdade de renda.  \n",
        "- **Government expenditure on education, total (% of government expenditure):** Investimento governamental em educação.  \n",
        "- **Patent applications, residents:** Inovação e competitividade.  \n",
        "- **Income share held by lowest 20%:** Equidade econômica.  \n",
        "\n",
        "**2. Verificação de Tamanhos dos Conjuntos**\n",
        "- Para cada variável-alvo, analisei os tamanhos dos conjuntos de treino e teste, identificando variáveis com conjuntos pequenos, como:  \n",
        "  - **Gini index (World Bank estimate).**  \n",
        "  - **Income share held by lowest 20%.**  \n",
        "\n",
        "---\n",
        "\n",
        "### Decisões Tomadas e Justificativas\n",
        "\n",
        "**1. Manutenção de Todas as Variáveis-Alvo**  \n",
        "- **Decisão:** Mantive todas as variáveis-alvo no processo inicial, independentemente do tamanho do conjunto de dados.  \n",
        "- **Justificativa:** Garante uma análise abrangente antes de decidir pela remoção ou alteração de qualquer variável.  \n",
        "\n",
        "**2. Documentação Rigorosa**  \n",
        "- **Decisão:** Documentei detalhadamente todas as etapas do processo.  \n",
        "- **Justificativa:** A transparência é essencial para revisões e facilita a replicação do projeto.  \n",
        "\n",
        "**3. Revisão de Variáveis com Poucos Dados**  \n",
        "- **Decisão:** Considerarei técnicas de amostragem, imputação ou exclusão para variáveis com poucos dados, caso necessário.  \n",
        "- **Justificativa:** Garantir que apenas variáveis robustas sejam usadas no modelo final.  \n",
        "\n",
        "---\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "**1. Desenvolvimento do Modelo Preditivo**  \n",
        "- Implementar modelos de aprendizado de máquina para prever cada variável-alvo.  \n",
        "- Escolher algoritmos apropriados (regressão ou classificação, conforme necessário).  \n",
        "\n",
        "**2. Validação e Ajustes**  \n",
        "- Avaliar o desempenho dos modelos utilizando métricas como:  \n",
        "  - **RMSE e MAE:** Para variáveis contínuas.  \n",
        "  - **Precisão, recall e F1-score:** Para variáveis categóricas.  \n",
        "- Ajustar hiperparâmetros para melhorar a performance dos modelos.  \n",
        "\n",
        "**3. Exploração de Alternativas para Variáveis com Poucos Dados**  \n",
        "- Testar técnicas de:  \n",
        "  - Amostragem ou aumento dos dados.  \n",
        "  - Exclusão ou substituição dessas variáveis.  \n",
        "\n",
        "**4. Documentação Detalhada**  \n",
        "- Atualizar notebooks com:  \n",
        "  - Códigos otimizados.  \n",
        "  - Observações e insights obtidos durante o desenvolvimento dos modelos.  \n",
        "  - Resultados preliminares para cada variável-alvo.  \n",
        "\n",
        "---\n",
        "\n",
        "### Justificativa para o Planejamento\n",
        "Este planejamento reflete a necessidade de uma abordagem sistemática e detalhada para o desenvolvimento do modelo preditivo. A inclusão de todas as variáveis-alvo inicialmente permite explorar seu potencial completo, enquanto a validação rigorosa garante modelos robustos e confiáveis.\n",
        "\n",
        "---\n",
        "\n",
        "### Observações\n",
        "Este documento será atualizado conforme o progresso do projeto. As próximas etapas incluirão a implementação dos modelos e ajustes baseados nos resultados preliminares.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "443d5aae",
      "metadata": {
        "id": "443d5aae"
      },
      "source": [
        "## Planejamento do Projeto - Parte 14\n",
        "\n",
        "\n",
        "### Atualizações do Projeto\n",
        "\n",
        "Nesta etapa, finalizei o ajuste e treinamento de modelos preditivos para todas as variáveis-alvo nos pilares Ambiental, Social e Governança. Também consolidei os resultados ajustados em uma base de dados chamada **resultados_ajustados.csv**, que foi salva na pasta principal de dados do projeto.\n",
        "\n",
        "---\n",
        "\n",
        "### Análises Realizadas\n",
        "\n",
        "**Ajustes de Hiperparâmetros**  \n",
        "- Realizei ajustes de hiperparâmetros para os modelos **Random Forest** e **XGBoost** utilizando as seguintes configurações:  \n",
        "  - **Random Forest:** Testei diferentes números de estimadores e profundidades máximas.  \n",
        "  - **XGBoost:** Ajustei a taxa de aprendizado e o número de estimadores.  \n",
        "- Documentei os desempenhos de **R²**, **RMSE** e **MAE** para cada modelo e variável-alvo.  \n",
        "\n",
        "**Resultados Consolidados**  \n",
        "- O desempenho dos modelos foi analisado e os resultados salvos em **resultados_ajustados.csv**.  \n",
        "- Algumas variáveis apresentaram desempenhos mais desafiadores, especialmente aquelas com poucos dados ou padrões muito complexos:  \n",
        "  - **Exemplo:** *Energy use*, *Forest area* e *Adjusted savings* tiveram resultados medianos em **XGBoost**.  \n",
        "  - Variáveis como *Gini index* e *Income share held by lowest 20%* enfrentaram limitações devido ao número reduzido de amostras.  \n",
        "\n",
        "---\n",
        "\n",
        "### Decisões Tomadas e Justificativas\n",
        "\n",
        "**Consolidar Resultados:**  \n",
        "- **Decisão:** Salvar os resultados ajustados em um arquivo CSV para facilitar a consulta futura e o monitoramento do progresso.  \n",
        "- **Justificativa:** Essa abordagem permite comparações rápidas e clareza no acompanhamento das métricas de cada modelo.  \n",
        "\n",
        "**Foco em Modelos de Desempenho Superior:**  \n",
        "- **Decisão:** Modelos com resultados consistentes, como **Random Forest** e **XGBoost**, continuarão sendo ajustados para as variáveis mais desafiadoras.  \n",
        "- **Justificativa:** Isso otimiza o tempo e garante maior precisão nos resultados finais.  \n",
        "\n",
        "**Documentação dos Processos:**  \n",
        "- **Decisão:** Atualizar todas as etapas no notebook correspondente, incluindo gráficos e insights dos ajustes realizados.  \n",
        "- **Justificativa:** Manter uma documentação clara é essencial para revisões e possíveis colaborações futuras.  \n",
        "\n",
        "---\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "**Validação e Ajustes de Modelos:**  \n",
        "- Revisar variáveis com baixo desempenho e decidir se será necessário aplicar técnicas de pré-processamento adicionais.  \n",
        "- Refinar os hiperparâmetros em variáveis mais desafiadoras ou reavaliar a inclusão de certas variáveis no modelo final.  \n",
        "\n",
        "**Exploração de Alternativas para Variáveis com Poucos Dados:**  \n",
        "- Testar abordagens como imputação ou agregação para melhorar a representatividade dessas variáveis.  \n",
        "\n",
        "**Documentação e Registro de Observações:**  \n",
        "- Consolidar os aprendizados e ajustes feitos nesta etapa no notebook e no planejamento.  \n",
        "\n",
        "---\n",
        "\n",
        "### Justificativa para o Planejamento\n",
        "\n",
        "Essas decisões foram tomadas para garantir que os modelos sejam otimizados antes de avançar para as próximas etapas do projeto. Registrar resultados e ajustes detalhadamente também facilita a comunicação dos avanços para stakeholders e garante reprodutibilidade.\n",
        "\n",
        "---\n",
        "\n",
        "### Observações\n",
        "\n",
        "Este documento será atualizado conforme o progresso do projeto e os ajustes futuros forem realizados.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51545aa6",
      "metadata": {
        "id": "51545aa6"
      },
      "source": [
        "## Planejamento do Projeto - Parte 15\n",
        "\n",
        "### Atualizações do Projeto\n",
        "Nesta etapa, foram realizadas ações cruciais para consolidar o progresso e ajustar o direcionamento do projeto. As atividades realizadas incluíram:\n",
        "\n",
        "1. **Geração do Dataset `resultados_ajustados.csv`:**\n",
        "   - Foram gerados resultados de métricas de desempenho (R², RMSE, MAE) para os modelos Random Forest e XGBoost em cada variável-alvo.\n",
        "   - Objetivo: Facilitar a análise comparativa e consolidar os resultados de ajustes de modelos.\n",
        "\n",
        "2. **Identificação de Problemas:**\n",
        "   - Algumas variáveis-alvo apresentaram um número insuficiente de amostras para a divisão de treino e teste.\n",
        "   - Isso resultou em ajustes limitados ou impossíveis para essas variáveis.\n",
        "\n",
        "3. **Decisão Estratégica:**\n",
        "   - Optou-se por **manter o dataset `resultados_ajustados.csv`** como referência, mas retornar ao dataset original (`ESGData_clean_final.csv`) para os próximos passos, garantindo maior flexibilidade e dados disponíveis para o ajuste de modelos.\n",
        "\n",
        "### Acertos\n",
        "- **Documentação:**\n",
        "  - Todas as etapas foram registradas, incluindo os problemas encontrados e as decisões tomadas.\n",
        "  - A geração do arquivo `resultados_ajustados.csv` permitiu a consolidação de métricas importantes.\n",
        "- **Diagnóstico de Variáveis com Poucos Dados:**\n",
        "  - A verificação da quantidade de amostras para cada variável-alvo revelou limitações que poderiam comprometer os ajustes.\n",
        "- **Redirecionamento Rápido:**\n",
        "  - Foi decidido retornar ao dataset original para maximizar a eficácia dos ajustes e evitar perda de informações.\n",
        "\n",
        "### Erros e Ajustes\n",
        "- **Erro no Uso de `resultados_ajustados.csv`:**\n",
        "  - A tentativa de usar este dataset para ajustes adicionais revelou-se inadequada, pois ele contém apenas métricas finais e não os dados originais.\n",
        "  - Ajuste: Redirecionamento ao dataset original.\n",
        "- **Número Insuficiente de Amostras:**\n",
        "  - Variáveis com menos de três amostras foram ignoradas para evitar erros em processos de validação cruzada.\n",
        "\n",
        "### Próximos Passos\n",
        "1. **Revisar e Corrigir Código:**\n",
        "   - Adaptar o pipeline para trabalhar com o dataset original (`ESGData_clean_final.csv`).\n",
        "   - Garantir a consistência na preparação de dados e no ajuste de modelos.\n",
        "\n",
        "2. **Validação e Ajustes de Modelos:**\n",
        "   - Refazer os ajustes de hiperparâmetros com base no dataset original.\n",
        "   - Registrar métricas para avaliação futura.\n",
        "\n",
        "3. **Commit e Controle de Versão:**\n",
        "   - Consolidar as alterações no repositório Git para garantir rastreabilidade.\n",
        "\n",
        "4. **Documentação:**\n",
        "   - Atualizar os notebooks com as novas abordagens e decisões.\n",
        "\n",
        "### Justificativa para o Redirecionamento\n",
        "O redirecionamento ao dataset original é necessário para maximizar o uso das informações disponíveis. Apesar de o arquivo `resultados_ajustados.csv` ser útil como referência, ele não suporta ajustes adicionais de modelos devido à falta de dados completos.\n",
        "\n",
        "### Observações\n",
        "Este planejamento mantém a transparência e assegura que cada etapa do projeto esteja alinhada aos objetivos gerais. O foco permanece em criar modelos robustos e bem ajustados para cada variável-alvo.\n",
        "\n",
        "Próxima etapa: Commit das atualizações e correção do pipeline para trabalhar com o dataset original."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b48e7475",
      "metadata": {
        "id": "b48e7475"
      },
      "source": [
        "## Planejamento do Projeto - Parte 16\n",
        "\n",
        "### **Status Atual do Projeto**\n",
        "1. **Desenvolvimento do Modelo**: Concluído.\n",
        "   - Modelos ajustados com Random Forest e XGBoost para as variáveis-alvo.\n",
        "   - Métricas robustas para as variáveis `Adjusted savings`, `Forest area` e `Literacy rate`.\n",
        "2. **Análise e Documentação**: Finalizadas.\n",
        "   - Documentação detalhada do processo foi registrada no notebook.\n",
        "   - Resultados salvos em arquivos CSV para referência futura.\n",
        "3. **Resultados Salvos**:\n",
        "   - `../data/resultados_finais_modelos.csv`\n",
        "   - `../data/resultados_finais_modelos_restantes.csv`.\n",
        "\n",
        "## **Documentação do Desenvolvimento do Modelo**\n",
        "\n",
        "### 1. Análise dos Gráficos e Dados das Variáveis\n",
        "\n",
        "Minha análise inicial foi focada em entender a distribuição das variáveis-alvo para identificar possíveis problemas nos dados, como valores ausentes, discrepâncias e a necessidade de transformações. Para isso, eu gerei gráficos de histogramas para cada variável-alvo, utilizando transformações logarítmica e raiz quadrada.\n",
        "**Principais Descobertas:**\n",
        "- Algumas variáveis apresentaram distribuições assimétricas, o que exigiu transformações.\n",
        "- A transformação logarítmica mostrou-se mais eficaz para normalizar variáveis como `Population density` e `Energy use`.\n",
        "- Identifiquei variáveis com valores discrepantes, que poderiam impactar negativamente a modelagem.\n",
        "\n",
        "### 2. Ajustes e Transformações Aplicados\n",
        "\n",
        "Com base na análise inicial, apliquei transformações às variáveis-alvo e criei novas colunas no dataset para armazenar os valores transformados. Variáveis como `log_Energy_Use`, `log_Population_Density` e `log_Food_Production_Index` foram geradas e verificadas quanto à consistência dos dados.\n",
        "\n",
        "**Desafios Enfrentados:**\n",
        "- **Desafios nos índices:** Percebi que os índices de X (colunas de anos) e y (valores transformados) não eram compatíveis, resultando em \"índices comuns\" zerados.\n",
        "- **Correção:** Ajustei os índices de X e y para garantir o alinhamento, utilizando os nomes dos países como referência principal.\n",
        "\n",
        "**Resultados:**\n",
        "- As variáveis transformadas foram corretamente integradas ao dataset.\n",
        "- Resolvi problemas de alinhamento de índices que estavam bloqueando a modelagem.\n",
        "\n",
        "### 3. Tentativas Iniciais de Modelagem\n",
        "\n",
        "As primeiras tentativas de modelagem foram frustradas devido à falta de amostras suficientes após o alinhamento dos dados. Isso me levou a revisar e ajustar o pipeline de preparação dos dados:\n",
        "- Ajustei os critérios de seleção de variáveis e índices para melhorar a interseção entre X e y.\n",
        "- Validei manualmente os alinhamentos antes de prosseguir com a modelagem.\n",
        "\n",
        "**Resultados:**\n",
        "Após os ajustes:\n",
        "- Variáveis como `log_Energy_Use`, `log_Population_Density` e `log_Food_Production_Index` apresentaram amostras suficientes para modelagem.\n",
        "- Algumas variáveis adicionais (ex.: `Forest area` e `Literacy rate`) ainda enfrentaram desafios devido à falta de dados.\n",
        "\n",
        "### 4. Modelagem das Variáveis-Alvo\n",
        "\n",
        "**Modelagem Bem-Sucedida:**\n",
        "Para variáveis com dados adequados, ajustei modelos Random Forest e XGBoost, comparando os resultados com base nas métricas de desempenho: R², RMSE e MAE.\n",
        "\n",
        "- **`Adjusted savings: natural resources depletion (% of GNI)`**\n",
        "  - **Random Forest:** R²=0.966, RMSE=0.705, MAE=0.336\n",
        "  - **XGBoost:** R²=0.939, RMSE=0.939, MAE=0.338\n",
        "\n",
        "- **`Forest area (% of land area)`**\n",
        "  - **Random Forest:** R²=1.000, RMSE=0.140, MAE=0.096\n",
        "  - **XGBoost:** R²=0.996, RMSE=0.504, MAE=0.320\n",
        "\n",
        "- **`Literacy rate, adult total (% of people ages 15 and above)`**\n",
        "  - **Random Forest:** R²=0.902, RMSE=2.804, MAE=1.724\n",
        "  - **XGBoost:** R²=0.862, RMSE=3.317, MAE=1.657\n",
        "\n",
        "**Desafios Adicionais:**\n",
        "- Para algumas variáveis com poucos dados disponíveis, como `Adjusted savings`, `Forest area` e `Literacy rate`, enfrentei desafios que exigiram um tratamento mais cuidadoso. Apesar disso, consegui modelá-las com bons resultados.\n",
        "\n",
        "### 5. Conclusão\n",
        "\n",
        "Os modelos individuais para variáveis-alvo específicas foram desenvolvidos e ajustados com sucesso, resultando em métricas robustas para variáveis como `Adjusted savings`, `Forest area` e `Literacy rate`. No entanto, a integração final das variáveis-alvo em um **ESG Risk Score consolidado** ainda está em andamento.\n",
        "\n",
        "O pipeline criado é replicável e flexível, permitindo ajustes e expansões futuras conforme necessário.\n",
        "\n",
        "---\n",
        "\n",
        "### Lições Aprendidas\n",
        "1. **Importância do Alinhamento de Dados**: Resolver as discrepâncias entre índices de diferentes variáveis foi crucial para garantir a consistência na modelagem.\n",
        "2. **Flexibilidade na Modelagem**: Testar transformações (logarítmica, normalização) foi essencial para lidar com a heterogeneidade dos dados.\n",
        "3. **Documentação e Monitoramento Constantes**: Documentar cada etapa facilitou a identificação de problemas e permitiu ajustes rápidos e eficazes.\n",
        "\n",
        "---\n",
        "\n",
        "### Próximos Passos\n",
        "1. **Integração do ESG Risk Score**:\n",
        "   - Normalizar os resultados de cada pilar (Ambiental, Social, Governança).\n",
        "   - Definir os pesos para cada variável representativa e calcular o score final.\n",
        "   - Testar e validar o ESG Risk Score para garantir sua eficácia na previsão de riscos ESG.\n",
        "\n",
        "2. **Deploy e Monitoramento**:\n",
        "   - Após concluir a integração, implementar o deploy do modelo em um ambiente funcional.\n",
        "   - Criar um pipeline de monitoramento para acompanhar o desempenho do modelo em produção."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49fd17cd",
      "metadata": {
        "id": "49fd17cd"
      },
      "source": [
        "## Planejamento do Projeto - Parte 17\n",
        "\n",
        "\n",
        "Neste reta final, foquei na consolidação e validação do ESG Risk Score, abordando as etapas finais da modelagem e realizando as correções necessárias no pipeline de dados e modelos. A seguir, detalho as ações e ajustes realizados:\n",
        "\n",
        "---\n",
        "\n",
        "### Atividades Realizadas\n",
        "\n",
        "**1. Correções nos Caminhos dos Modelos:**  \n",
        "- Corrigi os caminhos de salvamento e carregamento dos modelos para o diretório `../modelos_deploy_src`, garantindo consistência e funcionamento correto do pipeline.  \n",
        "\n",
        "**2. Reconstrução de X_teste:**  \n",
        "- Recriei o conjunto de dados `X_teste` para alinhá-lo às colunas e ao formato utilizado no treinamento dos modelos.  \n",
        "- Solucionei problemas relacionados a colunas inexistentes, ajustando as features de `X_teste` para manter compatibilidade com os modelos salvos.  \n",
        "\n",
        "**3. Normalização das Previsões:**  \n",
        "- Carreguei os modelos salvos e gerei previsões para as variáveis representativas dos pilares ESG:  \n",
        "  - **Ambiental:** `Forest area (% of land area)`.  \n",
        "  - **Social:** `Literacy rate, adult total (% of people ages 15 and above)`.  \n",
        "- Normalizei as previsões utilizando `MinMaxScaler`, garantindo que todas estivessem na mesma escala (0 a 1).  \n",
        "\n",
        "**4. Cálculo do ESG Risk Score:**  \n",
        "- Apliquei pesos aos pilares ESG:  \n",
        "  - **Ambiental:** 0.7  \n",
        "  - **Social:** 0.3  \n",
        "- Calculei o ESG Risk Score consolidado somando os scores ponderados de cada pilar.  \n",
        "\n",
        "**5. Validação e Visualização:**  \n",
        "- Gerei visualizações que mostram os ESG Risk Scores por pilar e o score total.  \n",
        "- Interpretei os resultados para garantir que refletissem adequadamente os fatores ESG considerados.  \n",
        "\n",
        "---\n",
        "\n",
        "### Insights Obtidos\n",
        "\n",
        "**1. Limitações dos Dados e Modelos:**  \n",
        "- Devido a dados incompletos e limitações de performance, o pilar de **Governança** não foi incluído na consolidação do ESG Risk Score.  \n",
        "- Apenas duas variáveis principais foram utilizadas, mas apresentaram resultados robustos em termos de predição.  \n",
        "\n",
        "**2. Interpretação do ESG Risk Score:**  \n",
        "- O score consolidado indica o risco relativo associado aos pilares **Ambiental** e **Social**, sendo maior para países com problemas significativos nesses aspectos.  \n",
        "- A ausência de benchmarks dificulta uma análise qualitativa mais profunda, mas os resultados são promissores para o contexto explorado.  \n",
        "\n",
        "**3. Preparação para o Deploy:**  \n",
        "- O pipeline de cálculo do ESG Risk Score foi ajustado e está pronto para integração no ambiente de deploy.  \n",
        "\n",
        "---\n",
        "\n",
        "### Próximos Passos\n",
        "\n",
        "**1. Deploy do Modelo ESG Risk Score:**  \n",
        "- Implementar o deploy utilizando **Flask** e **Docker**.  \n",
        "- Configurar uma API para que o ESG Risk Score possa ser acessado em tempo real.  \n",
        "\n",
        "**2. Monitoramento e Manutenção:**  \n",
        "- Implementar um pipeline de monitoramento para acompanhar o desempenho do modelo em produção.  \n",
        "- Planejar um mecanismo de retreinamento automatizado com base em mudanças nos dados ou no ambiente.  \n",
        "\n",
        "**3. Documentação Final:**  \n",
        "- Atualizar toda a documentação do projeto, incluindo decisões de design, resultados obtidos e lições aprendidas.  \n",
        "- Preparar um relatório final consolidado para apresentação.  \n",
        "\n",
        "**4. Expansão Futura:**  \n",
        "- Explorar a inclusão do pilar de **Governança** no ESG Risk Score.  \n",
        "- Ampliar a base de dados para melhorar a cobertura e a representatividade das variáveis ESG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e4fb92da",
      "metadata": {
        "id": "e4fb92da"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Planejamento do Projeto - Parte 18\n",
        "\n",
        "## Resumo das Atividades Realizadas\n",
        "\n",
        "Nesta etapa, finalizei a consolidação e validação do pipeline para cálculo do ESG Risk Score, resolvendo problemas técnicos e inconsistências que estavam bloqueando o progresso do deploy. As ações foram divididas em duas frentes principais: ajustes na infraestrutura do ambiente e finalização do endpoint de previsão.\n",
        "\n",
        "---\n",
        "\n",
        "## Atividades Realizadas\n",
        "\n",
        "**1. Alinhamento de Versões e Configuração do Ambiente:**  \n",
        "- Resolvi inconsistências entre os ambientes base e virtual (**esg_model_env**), sincronizando versões do Python, NumPy e Scikit-learn.  \n",
        "- Verifiquei e atualizei o arquivo `requirements.txt`, garantindo a instalação correta de dependências no ambiente virtual.  \n",
        "- Usei **pip freeze** para comparar e corrigir divergências de dependências entre os dois ambientes.  \n",
        "\n",
        "**2. Carregamento de Modelos e Ajuste de Features:**  \n",
        "- Identifiquei e carreguei os modelos para as variáveis representativas:  \n",
        "  - **Ambiental:** `Forest area (% of land area)`.  \n",
        "  - **Social:** `Literacy rate, adult total (% of people ages 15 and above)`.  \n",
        "- Confirmei que as features utilizadas no treinamento estavam completas e consistentes, usando `feature_names_in_`.  \n",
        "- Resolvi problemas relacionados a arquivos incompatíveis devido às versões anteriores de bibliotecas.  \n",
        "\n",
        "**3. Implementação do Endpoint de Previsão:**  \n",
        "- Configurei um endpoint `/predict` no Flask para receber JSONs como entrada e retornar previsões.  \n",
        "- Criei o arquivo **`entrada.json`**, contendo os dados de teste (anos de 1961 a 2019 com valores fictícios), salvando-o na pasta `src`.  \n",
        "- Realizei testes com `curl` para garantir que o endpoint funcionasse corretamente, retornando as previsões para as variáveis representativas.  \n",
        "  - Exemplos de previsões retornadas:  \n",
        "    ```json\n",
        "    {\n",
        "      \"Forest area (% of land area)\": [28.95, 31.32, 33.28],\n",
        "      \"Literacy rate, adult total (% of people ages 15 and above)\": [36.34, 39.07, 43.95]\n",
        "    }\n",
        "    ```  \n",
        "\n",
        "**4. Resolução de Conflitos de Porta e Servidor:**  \n",
        "- Identifiquei e encerrei processos em conflito utilizando o comando `lsof -i :5000` seguido de `kill -9 <PID>`.  \n",
        "- Reiniciei o servidor Flask com sucesso, validando que estava ativo e responsivo no endpoint `http://127.0.0.1:5000`.  \n",
        "\n",
        "---\n",
        "\n",
        "## Insights Obtidos\n",
        "\n",
        "**1. Controle de Dependências:**  \n",
        "- Manter as dependências alinhadas entre os ambientes é essencial para evitar erros no carregamento de modelos e execução do pipeline.  \n",
        "\n",
        "**2. Teste do Endpoint:**  \n",
        "- A utilização de dados fictícios e o arquivo `entrada.json` facilitou a verificação do endpoint, garantindo que o formato de entrada fosse consistente com as features esperadas pelos modelos.  \n",
        "\n",
        "**3. Configuração de Servidor:**  \n",
        "- Problemas comuns como conflitos de porta podem ser resolvidos rapidamente com comandos apropriados para monitorar e encerrar processos em conflito.  \n",
        "\n",
        "---\n",
        "\n",
        "## Próximos Passos\n",
        "\n",
        "**1. Integração e Validação do Deploy Final:**  \n",
        "- Implementar o deploy utilizando **Docker** para maior portabilidade.  \n",
        "- Testar o pipeline de previsão em diferentes ambientes, incluindo contêiners.  \n",
        "\n",
        "**2. Monitoramento e Manutenção:**  \n",
        "- Desenvolver um pipeline para monitoramento de desempenho dos modelos.  \n",
        "- Implementar retreinamento automático com base em novos dados.  \n",
        "\n",
        "**3. Documentação Final e Apresentação:**  \n",
        "- Consolidar todas as etapas realizadas em um relatório final para apresentação.  \n",
        "- Incluir visualizações dos resultados e lições aprendidas.  \n",
        "\n",
        "**4. Expansão do Escopo:**  \n",
        "- Avaliar a possibilidade de incluir o pilar de **Governança** no ESG Risk Score.  \n",
        "- Expandir a base de dados para melhorar a representatividade das variáveis ESG.  "
      ],
      "metadata": {
        "id": "HiZt3GQNDnVi"
      },
      "id": "HiZt3GQNDnVi"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W-o8HFtyDd7b"
      },
      "id": "W-o8HFtyDd7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oK-aq9FYDe75"
      },
      "id": "oK-aq9FYDe75"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RmcZeJndDXjM"
      },
      "id": "RmcZeJndDXjM"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7xSpKegdDC47"
      },
      "id": "7xSpKegdDC47"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a4b434",
      "metadata": {
        "id": "f5a4b434"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (esg_model_env)",
      "language": "python",
      "name": "esg_model_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}